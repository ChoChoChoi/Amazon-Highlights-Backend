{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaedadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"sagemaker>=2.48.0\" \"transformers==4.6.1\" \"datasets[s3]==1.6.2\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2592c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install \"s3transfer<0.7.0,>=0.6.0\" \"botocore<1.22.9,>=1.22.8\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92315699",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import IPython\n",
    "!conda install -c conda-forge ipywidgets -y\n",
    "IPython.Application.instance().kernel.do_shutdown(True) # timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e31a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    import torch # module이 뭐가 필요한지 확인, 도커 requirement로 하는 방법도 있음\n",
    "except ImportError:\n",
    "    os.system('pip install torch==1.10.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48658074",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import IPython\n",
    "\n",
    "#install_needed = True\n",
    "install_needed = False\n",
    "\n",
    "if install_needed:\n",
    "    print(\"===> Installing deps and restarting kernel. Please change 'install_needed = False' and run this code cell again.\")\n",
    "    !{sys.executable} -m pip install -U transformers s3fs datasets # dependencies\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5a71729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create session and define role\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket = None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d19f4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3503802551214baea58513c2e2a12485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe734b0d5464be3b605448bfdbb5d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use pre-trained model\n",
    "\n",
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"philschmid/bart-large-cnn-samsum\")\n",
    "\n",
    "conversation = '''Jeff: Can I train a 🤗 Transformers model on Amazon SageMaker? \n",
    "Philipp: Sure you can use the new Hugging Face Deep Learning Container. \n",
    "Jeff: ok.\n",
    "Jeff: and how can I get started? \n",
    "Jeff: where can I find documentation? \n",
    "Philipp: ok, ok you can find everything here. https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugging-face                                           \n",
    "'''\n",
    "summarizer(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bea1386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'The Eiffel Tower is 324 metres tall and the second tallest free-standing structure in France after the Millau Viaduct. It was the first structure to reach a height of 300 metres and it is now taller than the Chrysler Building by 5.2 metres.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deploy\n",
    "\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "    'HF_MODEL_ID':'philschmid/bart-large-cnn-samsum', # s3에 업로드 한 후 tar로 옮겨야 하나요?\n",
    "    'HF_TASK':'summarization'\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    transformers_version='4.17.0',\n",
    "    pytorch_version='1.10.2',\n",
    "    py_version='py38',\n",
    "    env=hub,\n",
    "    role=role, # IAM role\n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference, create endpoint\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1, # number of instances\n",
    "    instance_type='ml.m5.xlarge', # ec2 instance type\n",
    "    wait=False\n",
    ")\n",
    "\n",
    "# request - s3 load (hard limit: 6MB), result: dynamoDB\n",
    "# streaming(real-time)/batch(input,output-s3) -> batch 추론, 비동기\n",
    "# \n",
    "predictor.predict({\n",
    "    'inputs': \"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\"\n",
    "})\n",
    "\n",
    "# batch\n",
    "batch_job = huggingface_estimator.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    strategy='SingleRecord')\n",
    "\n",
    "\n",
    "batch_job.transform(\n",
    "    data='s3://s3-uri-to-batch-data',\n",
    "    content_type='application/json',    \n",
    "    split_type='Line')\n",
    "\n",
    "\n",
    "# boto3 3줄\n",
    "# sdk -> 대근님 코드 참고, api 호출로 한번에 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e7478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictor\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.local import LocalSession\n",
    "\n",
    "endpoint_name = huggingface_model\n",
    "local_sess = LocalSession()\n",
    "\n",
    "model_predictor = Predictor(\n",
    "    endpoint_name = endpoint_name,\n",
    "    sagemaker_session = local_sess,\n",
    "    serializer=CSVSerializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6d0dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait for creating endpoint\n",
    "# (1) deploy가 진행되는 동안 다른 셀을 작동시키기 위함\n",
    "# (2) deploy 과정이 주피터 랩이 아닌 AWS에서 진행된다는 것을 보여주기 위함\n",
    "from IPython.core.display import display, HTML\n",
    "def make_endpoint_link(region, endpoint_name, endpoint_task):\n",
    "    endpoint_link = f'<b><a target=\"blank\" href=\"https://console.aws.amazon.com\"'\n",
    "    return endpoint_link\n",
    "\n",
    "endpoint_link = make_endpoint_link(region, model_predictor.endpoint_name, '[Dep]')\n",
    "display(HTML(endpoint_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3bd63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.wait_for_endpoint(model_predictor.endpoint_name, poll=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118ceef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete endpoint\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p38",
   "language": "python",
   "name": "conda_tensorflow2_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
